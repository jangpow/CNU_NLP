{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfTcLf-rjaWd"
      },
      "source": [
        "#### **Attention is All You Need (NIPS 2017)** 실습\n",
        "* <b>(뉴스 데이터셋)</b> 한국어 문장을 영어 문장으로 번역합니다.\n",
        "* 본 코드는 기본적으로 **Transformer** 논문의 내용을 최대한 따릅니다.\n",
        "    * 본 논문은 **딥러닝 기반의 자연어 처리** 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "    * 2020년 기준 가장 뛰어난 번역 모델들은 본 논문에서 제안한 **Transformer 기반의 아키텍처**를 따르고 있습니다.\n",
        "* 코드 실행 전에 **[런타임]** → **[런타임 유형 변경]** → 유형을 **GPU**로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXXXOxNzeLpj"
      },
      "source": [
        "#### <b>한글 출력을 위한 폰트 설치</b>\n",
        "\n",
        "* 설치 이후에 수동으로 <b>[런타임]</b> - <b>[런타임 다시 시작]</b> 버튼을 눌러 재시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65nhszH6eNPt",
        "outputId": "7d3162a1-5672-4706-a7c9-c4b4be266f6b"
      },
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epJDFH3k03M6"
      },
      "source": [
        "#### <b>BLEU Score 계산을 위한 라이브러리 업데이트</b>\n",
        "\n",
        "* <b>[Restart Runtime]</b> 버튼을 눌러 런타임을 재시작할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrr-S31b031u",
        "outputId": "efc7af8f-5ed0-4bf8-9c21-c5d922da6702"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OdH8Empjyxa"
      },
      "source": [
        "#### <b>한글 토큰화 라이브러리 설치하기</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2O0iSKl2mT_",
        "outputId": "5df7f9e7-63e5-4ab6-9ec9-91be137c4152"
      },
      "source": [
        "!pip3 install konlpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 608 kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5h73Lh9j2GW"
      },
      "source": [
        "#### <b>데이터셋 다운로드</b>\n",
        "\n",
        "* 한영 번역 데이터셋을 다운로드하여 파이썬 객체로 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdPZWIgl2oeF",
        "outputId": "ec24859e-2cf2-41e4-f2b3-36bf2ba2801c"
      },
      "source": [
        "# 한영 번역 데이터셋을 포함하는 저장소\n",
        "!git clone https://github.com/ndb796/korean-parallel-corpora"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'korean-parallel-corpora'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 0 (delta 0), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (131/131), 17.67 MiB | 7.01 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iBk4-k2qR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a231800e-2406-479b-b070-0eede5970887"
      },
      "source": [
        "# 데이터셋이 저장될 폴더 생성\n",
        "!mkdir -p ./dataset\n",
        "\n",
        "# 압축 해제\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.train.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.test.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.dev.tar.gz -C ./dataset\n",
        "\n",
        "# 학습(training) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.train.en ./dataset/train.en\n",
        "!mv ./dataset/korean-english-park.train.ko ./dataset/train.ko\n",
        "\n",
        "# 평가(validation) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.dev.en ./dataset/dev.en\n",
        "!mv ./dataset/korean-english-park.dev.ko ./dataset/dev.ko\n",
        "\n",
        "# 테스트(test) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.test.en ./dataset/test.en\n",
        "!mv ./dataset/korean-english-park.test.ko ./dataset/test.ko"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean-english-park.train.en\n",
            "korean-english-park.train.ko\n",
            "korean-english-park.test.en\n",
            "korean-english-park.test.ko\n",
            "korean-english-park.dev.en\n",
            "korean-english-park.dev.ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_JbLlFqOpAo"
      },
      "source": [
        "#### <b>데이터셋 읽어 확인하기</b>\n",
        "\n",
        "* 학습, 평가, 테스트 데이터셋을 각각 읽어 문장 데이터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcTMM_Em2rUJ"
      },
      "source": [
        "korean_lines_train = open(\"./dataset/train.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_train = open(\"./dataset/train.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_val = open(\"./dataset/dev.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_val = open(\"./dataset/dev.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_test = open(\"./dataset/test.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_test = open(\"./dataset/test.en\", 'r', encoding='utf-8').readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np7PF8SFkBNv",
        "outputId": "b58bf264-f3a6-4213-f402-e848a3e8d427"
      },
      "source": [
        "print(f\"한글 문장 학습 데이터 개수: {len(korean_lines_train)}개\")\n",
        "print(f\"영어 문장 학습 데이터 개수: {len(english_lines_train)}개\")\n",
        "\n",
        "print(f\"한글 문장 평가 데이터 개수: {len(korean_lines_val)}개\")\n",
        "print(f\"영어 문장 평가 데이터 개수: {len(english_lines_val)}개\")\n",
        "\n",
        "print(f\"한글 문장 테스트 데이터 개수: {len(korean_lines_test)}개\")\n",
        "print(f\"영어 문장 테스트 데이터 개수: {len(english_lines_test)}개\")\n",
        "\n",
        "index = 777\n",
        "print(f\"{index + 1}번째 학습용 한글 문장:\", korean_lines_train[index], end='')\n",
        "print(f\"{index + 1}번째 학습용 영어 문장:\", english_lines_train[index], end='')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한글 문장 학습 데이터 개수: 94123개\n",
            "영어 문장 학습 데이터 개수: 94123개\n",
            "한글 문장 평가 데이터 개수: 1000개\n",
            "영어 문장 평가 데이터 개수: 1000개\n",
            "한글 문장 테스트 데이터 개수: 2000개\n",
            "영어 문장 테스트 데이터 개수: 2000개\n",
            "778번째 학습용 한글 문장: 지금 21살인 유는 학교에 가기 전 서너시간 동안 컴퓨터 통신에 끼어들기 위해 새벽 5시에 침대에서 일어나 나온다.\n",
            "778번째 학습용 영어 문장: Now Yu, 21, drags herself out of bed at 5 a.m. to squeeze in a few hours online before school.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcLKB3BRkDKW"
      },
      "source": [
        "#### <b>단어 사전 만들기 </b>\n",
        "\n",
        "* 단어 사전 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWpaBry12tjd"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.UNK = '<unk>'\n",
        "        self.PAD = '<pad>'\n",
        "        self.SOS = '<sos>'\n",
        "        self.EOS = '<eos>'\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.word2count = {}\n",
        "\n",
        "    # 하나의 문장(sentence)에 포함된 모든 토큰을 추가하는 함수\n",
        "    def add_tokens(self, tokens):\n",
        "        for word in tokens:\n",
        "            if word in self.word2count:\n",
        "                self.word2count[word] += 1\n",
        "            else:\n",
        "                self.word2count[word] = 1\n",
        "\n",
        "    def preprocess(self, min_count):\n",
        "        # 사용하지 않을 단어 집합\n",
        "        trim_words = set()\n",
        "        for word, count in self.word2count.items():\n",
        "            if count < min_count:\n",
        "                trim_words.add(word)\n",
        "\n",
        "        # 실제로 사용할 단어만 남기기\n",
        "        words = set(self.word2count.keys()) - trim_words\n",
        "        words = [self.UNK, self.PAD, self.SOS, self.EOS] + list(words)\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        for i, word in enumerate(words):\n",
        "            self.word2idx[word] = i\n",
        "            self.idx2word[i] = word"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSB5vFULkecQ"
      },
      "source": [
        "#### <b>문장 토큰화</b>\n",
        "\n",
        "* 먼저 한글 문장 및 영어 문장 데이터셋에 대하여 토큰화를 수행합니다.\n",
        "* 토큰화를 위해 특수문자 제거 함수를 정의하고 객체를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDH1f2gqlxO-"
      },
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "def clean_string(string):\n",
        "    string = string.strip() # 앞뒤로 존재하는 공백 제거\n",
        "    string = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', string) # 특수문자 제거\n",
        "    return string.strip().lower() # 소문자로 변환하여 반환\n",
        "\n",
        "okt = Okt() # 한글 형태소 분석기"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fP80_AZmSC8"
      },
      "source": [
        "* 학습(training) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyKq4u8pmRlM",
        "outputId": "d939b674-8f78-4c9b-f37c-77fb8d90fbad"
      },
      "source": [
        "tokenized_korean_lines_train = []\n",
        "tokenized_english_lines_train = []\n",
        "\n",
        "min_length = 4 # 단어의 개수가 4개 이상인 학습 문장 쌍만 사용\n",
        "max_length = 50 # 단어의 개수가 50개 이하인 학습 문장 쌍만 사용\n",
        "\n",
        "for i in range(len(korean_lines_train)):\n",
        "    korean = korean_lines_train[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_train[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    if len(korean_tokens) < min_length or len(korean_tokens) > max_length:\n",
        "        continue\n",
        "    if len(english_tokens) < min_length or len(english_tokens) > max_length:\n",
        "        continue\n",
        "\n",
        "    tokenized_korean_lines_train.append(korean_tokens)\n",
        "    tokenized_english_lines_train.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 4000 == 0:\n",
        "        print(f\"학습 데이터셋 토큰화: {i + 1}/{len(korean_lines_train)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋 토큰화: 4000/94123\n",
            "학습 데이터셋 토큰화: 8000/94123\n",
            "학습 데이터셋 토큰화: 12000/94123\n",
            "학습 데이터셋 토큰화: 16000/94123\n",
            "학습 데이터셋 토큰화: 20000/94123\n",
            "학습 데이터셋 토큰화: 24000/94123\n",
            "학습 데이터셋 토큰화: 28000/94123\n",
            "학습 데이터셋 토큰화: 32000/94123\n",
            "학습 데이터셋 토큰화: 36000/94123\n",
            "학습 데이터셋 토큰화: 40000/94123\n",
            "학습 데이터셋 토큰화: 44000/94123\n",
            "학습 데이터셋 토큰화: 48000/94123\n",
            "학습 데이터셋 토큰화: 52000/94123\n",
            "학습 데이터셋 토큰화: 56000/94123\n",
            "학습 데이터셋 토큰화: 60000/94123\n",
            "학습 데이터셋 토큰화: 64000/94123\n",
            "학습 데이터셋 토큰화: 68000/94123\n",
            "학습 데이터셋 토큰화: 72000/94123\n",
            "학습 데이터셋 토큰화: 76000/94123\n",
            "학습 데이터셋 토큰화: 80000/94123\n",
            "학습 데이터셋 토큰화: 84000/94123\n",
            "학습 데이터셋 토큰화: 88000/94123\n",
            "학습 데이터셋 토큰화: 92000/94123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DerYg_C1nOk7"
      },
      "source": [
        "* 평가(validation) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrnkrbTnPoc",
        "outputId": "e997c2ee-d1c2-4ee5-ab61-da6b662ad917"
      },
      "source": [
        "tokenized_korean_lines_val = []\n",
        "tokenized_english_lines_val = []\n",
        "\n",
        "for i in range(len(korean_lines_val)):\n",
        "    korean = korean_lines_val[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_val[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_val.append(korean_tokens)\n",
        "    tokenized_english_lines_val.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"평가 데이터셋 토큰화: {i + 1}/{len(korean_lines_val)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평가 데이터셋 토큰화: 1000/1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_sP1Wn3pvQU"
      },
      "source": [
        "* 테스트(test) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxY4lieapyQj",
        "outputId": "55a93734-8e77-44ea-acb4-831cf2bcfd44"
      },
      "source": [
        "tokenized_korean_lines_test = []\n",
        "tokenized_english_lines_test = []\n",
        "\n",
        "for i in range(len(korean_lines_test)):\n",
        "    korean = korean_lines_test[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_test[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_test.append(korean_tokens)\n",
        "    tokenized_english_lines_test.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"테스트 데이터셋 토큰화: {i + 1}/{len(korean_lines_test)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터셋 토큰화: 1000/2000\n",
            "테스트 데이터셋 토큰화: 2000/2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxvJN5THq2hx"
      },
      "source": [
        "#### <b>단어 사전 만들기</b>\n",
        "\n",
        "* 최소 2번 이상 등장한 단어만 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNVKZ7NbrP2l",
        "outputId": "9f44163b-d01f-4d05-dfa6-87168d16af63"
      },
      "source": [
        "korean_voca = Vocabulary()\n",
        "english_voca = Vocabulary()\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    korean_voca.add_tokens(korean_tokens)\n",
        "    english_voca.add_tokens(english_tokens)\n",
        "\n",
        "korean_voca.preprocess(min_count=2)\n",
        "english_voca.preprocess(min_count=2)\n",
        "\n",
        "print(\"전체 한국어 단어 수:\", len(korean_voca.word2count))\n",
        "print(\"전체 영어 단어 수:\", len(english_voca.word2count))\n",
        "print(\"사용할 한국어 토큰 수:\", len(korean_voca.word2idx))\n",
        "print(\"사용할 영어 토큰 수:\", len(english_voca.word2idx))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 한국어 단어 수: 67029\n",
            "전체 영어 단어 수: 58833\n",
            "사용할 한국어 토큰 수: 40612\n",
            "사용할 영어 토큰 수: 35745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyKQjwAusyw",
        "outputId": "18a80731-2dd3-4165-9d26-8ebf028af963"
      },
      "source": [
        "print(korean_voca.word2idx['<pad>']) # 패딩(padding): 1\n",
        "print(korean_voca.word2idx['<sos>']) # <sos>: 2\n",
        "print(korean_voca.word2idx['<eos>']) # <eos>: 3\n",
        "print(korean_voca.word2idx['컴퓨터'])\n",
        "print(korean_voca.word2idx['사랑'])\n",
        "print(korean_voca.word2idx['기적'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "27263\n",
            "10976\n",
            "39660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQjD1bjVuvHt",
        "outputId": "781d7016-777a-4260-cac2-0d9055bc3e70"
      },
      "source": [
        "print(english_voca.word2idx['<pad>']) # 패딩(padding): 1\n",
        "print(english_voca.word2idx['<sos>']) # <sos>: 2\n",
        "print(english_voca.word2idx['<eos>']) # <eos>: 3\n",
        "print(english_voca.word2idx['computer'])\n",
        "print(english_voca.word2idx['love'])\n",
        "print(english_voca.word2idx['miracle'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "12121\n",
            "15847\n",
            "18646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw7jo7dmsHRW"
      },
      "source": [
        "* Unknown Token이 1개 이상 포함된 문장은 데이터셋에서 제외하여 다시 학습 데이터셋을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M717ROWBsFmM"
      },
      "source": [
        "unknown_threshold = 1\n",
        "\n",
        "preprocessed_korean_lines_train = []\n",
        "preprocessed_english_lines_train = []\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    is_used = True # 현재의 문장 쌍을 사용할지의 여부\n",
        "    for token in korean_tokens:\n",
        "        cnt = 0\n",
        "        if token not in korean_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "    for token in english_tokens:\n",
        "        cnt = 0\n",
        "        if token not in english_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "\n",
        "    if not is_used:\n",
        "        continue\n",
        "\n",
        "    preprocessed_korean_lines_train.append(korean_tokens)\n",
        "    preprocessed_english_lines_train.append(english_tokens)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg6lc1V4uDQ6",
        "outputId": "15b3618d-d656-43bb-999a-8d594c3fc8ee"
      },
      "source": [
        "print(\"사용할 한국어 학습 문장 수:\", len(preprocessed_korean_lines_train))\n",
        "print(\"사용할 영어 학습 문장 수:\", len(preprocessed_english_lines_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용할 한국어 학습 문장 수: 61029\n",
            "사용할 영어 학습 문장 수: 61029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH1SIu_i5mch",
        "outputId": "8f4ffa5e-202c-4682-bb38-0f9537ec2ff5"
      },
      "source": [
        "print(preprocessed_korean_lines_train[7777])\n",
        "print(preprocessed_english_lines_train[7777])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cnn', '의', '여론조사', '국장', '인', '키팅', '홀랜드', '는', '“', '이라크전', '발발', '직후', '부시', '의', '지지도', '는', '71', '였다', '”', '며', '“', '지지율', '40', '추락', '은', '베트남전', '당시', '린', '든', '존슨', '대통령', '과', '유사하다', '”', '고', '지적', '했다']\n",
            "['bushs', 'approval', 'rating', 'five', 'years', 'ago', 'at', 'the', 'start', 'of', 'the', 'iraq', 'war', 'was', '71', 'percent', 'and', 'that', '40point', 'drop', 'is', 'almost', 'identical', 'to', 'the', 'drop', 'president', 'lyndon', 'johnson', 'faced', 'during', 'the', 'vietnam', 'war', 'said', 'cnn', 'polling', 'director', 'keating', 'holland']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eItQjid_uzsB"
      },
      "source": [
        "#### <b>커스텀 데이터셋 클래스 작성하기</b>\n",
        "\n",
        "* 소스 문장(한국어)과 타겟 문장(영어)를 한 쌍으로 반환하는 데이터셋 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C7JV5PE5rmM"
      },
      "source": [
        "import copy\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, korean_lines, english_lines, max_seq_len):\n",
        "        self.korean_lines = korean_lines\n",
        "        self.english_lines = english_lines\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoder_input = self.get_encoder_input(self.korean_lines[index])\n",
        "        decoder_input = self.get_decoder_input(self.english_lines[index])\n",
        "\n",
        "        return encoder_input, decoder_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.korean_lines)\n",
        "\n",
        "    # 한글 문장 벡터화\n",
        "    def get_encoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, korean_voca.SOS)\n",
        "        tokens.append(korean_voca.EOS)\n",
        "        tokens = self.padding(tokens, korean_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, korean_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # 영어 문장 벡터화\n",
        "    def get_decoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, english_voca.SOS)\n",
        "        tokens.append(english_voca.EOS)\n",
        "        tokens = self.padding(tokens, english_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, english_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # max_seq_len보다 길이가 짧은 문장에 대해 <pad> 토큰 채우기\n",
        "    def padding(self, tokens, voca):\n",
        "        if len(tokens) < self.max_seq_len:\n",
        "            tokens += [voca.PAD] * (self.max_seq_len - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:self.max_seq_len]\n",
        "        return tokens\n",
        "\n",
        "    def word2idx(self, tokens, voca):\n",
        "        idx_list = []\n",
        "        for token in tokens:\n",
        "            try:\n",
        "                idx_list.append(voca.word2idx[token])\n",
        "            except KeyError:\n",
        "                idx_list.append(voca.word2idx[voca.UNK])\n",
        "        return idx_list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EObNRkSSvPfk"
      },
      "source": [
        "* 학습/평가/테스트 데이터셋 객체를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBsC-CRc5_F7"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = CustomDataset(preprocessed_korean_lines_train, preprocessed_english_lines_train, max_seq_len=80)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(tokenized_korean_lines_val, tokenized_english_lines_val, max_seq_len=80)\n",
        "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=128, num_workers=0)\n",
        "\n",
        "test_dataset = CustomDataset(tokenized_korean_lines_test, tokenized_english_lines_test, max_seq_len=80)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=128, num_workers=0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlKQSsxK6BdK",
        "outputId": "8e248646-0c94-47c0-b16b-cfa18e9130a4"
      },
      "source": [
        "# 하나의 배치에 포함되어 있는 문장을 출력합니다.\n",
        "for i, batch in enumerate(train_loader):\n",
        "    src = batch[0]\n",
        "    trg = batch[1]\n",
        "\n",
        "    print(f\"첫 번째 배치 크기: {src.shape}\")\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(src.shape[1]):\n",
        "        print(f\"인덱스 {i}: {src[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "    # 첫 번째 배치만 확인\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 크기: torch.Size([128, 80])\n",
            "인덱스 0: 2\n",
            "인덱스 1: 17719\n",
            "인덱스 2: 4360\n",
            "인덱스 3: 9015\n",
            "인덱스 4: 33129\n",
            "인덱스 5: 39389\n",
            "인덱스 6: 3\n",
            "인덱스 7: 1\n",
            "인덱스 8: 1\n",
            "인덱스 9: 1\n",
            "인덱스 10: 1\n",
            "인덱스 11: 1\n",
            "인덱스 12: 1\n",
            "인덱스 13: 1\n",
            "인덱스 14: 1\n",
            "인덱스 15: 1\n",
            "인덱스 16: 1\n",
            "인덱스 17: 1\n",
            "인덱스 18: 1\n",
            "인덱스 19: 1\n",
            "인덱스 20: 1\n",
            "인덱스 21: 1\n",
            "인덱스 22: 1\n",
            "인덱스 23: 1\n",
            "인덱스 24: 1\n",
            "인덱스 25: 1\n",
            "인덱스 26: 1\n",
            "인덱스 27: 1\n",
            "인덱스 28: 1\n",
            "인덱스 29: 1\n",
            "인덱스 30: 1\n",
            "인덱스 31: 1\n",
            "인덱스 32: 1\n",
            "인덱스 33: 1\n",
            "인덱스 34: 1\n",
            "인덱스 35: 1\n",
            "인덱스 36: 1\n",
            "인덱스 37: 1\n",
            "인덱스 38: 1\n",
            "인덱스 39: 1\n",
            "인덱스 40: 1\n",
            "인덱스 41: 1\n",
            "인덱스 42: 1\n",
            "인덱스 43: 1\n",
            "인덱스 44: 1\n",
            "인덱스 45: 1\n",
            "인덱스 46: 1\n",
            "인덱스 47: 1\n",
            "인덱스 48: 1\n",
            "인덱스 49: 1\n",
            "인덱스 50: 1\n",
            "인덱스 51: 1\n",
            "인덱스 52: 1\n",
            "인덱스 53: 1\n",
            "인덱스 54: 1\n",
            "인덱스 55: 1\n",
            "인덱스 56: 1\n",
            "인덱스 57: 1\n",
            "인덱스 58: 1\n",
            "인덱스 59: 1\n",
            "인덱스 60: 1\n",
            "인덱스 61: 1\n",
            "인덱스 62: 1\n",
            "인덱스 63: 1\n",
            "인덱스 64: 1\n",
            "인덱스 65: 1\n",
            "인덱스 66: 1\n",
            "인덱스 67: 1\n",
            "인덱스 68: 1\n",
            "인덱스 69: 1\n",
            "인덱스 70: 1\n",
            "인덱스 71: 1\n",
            "인덱스 72: 1\n",
            "인덱스 73: 1\n",
            "인덱스 74: 1\n",
            "인덱스 75: 1\n",
            "인덱스 76: 1\n",
            "인덱스 77: 1\n",
            "인덱스 78: 1\n",
            "인덱스 79: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bieO3YwVvmLY"
      },
      "source": [
        "#### **Multi Head Attention 아키텍처**\n",
        "\n",
        "* 어텐션(attention)은 <b>세 가지 요소</b>를 입력으로 받습니다.\n",
        "    * <b>쿼리(queries)</b>\n",
        "    * <b>키(keys)</b>\n",
        "    * <b>값(values)</b>\n",
        "    * 현재 구현에서는 Query, Key, Value의 차원이 모두 같습니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRX0AoF1voKW"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
        "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
        "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # query: [batch_size, query_len, hidden_dim]\n",
        "        # key: [batch_size, key_len, hidden_dim]\n",
        "        # value: [batch_size, value_len, hidden_dim]\n",
        " \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Q: [batch_size, query_len, hidden_dim]\n",
        "        # K: [batch_size, key_len, hidden_dim]\n",
        "        # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "        # K: [batch_size, n_heads, key_len, head_dim]\n",
        "        # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "        # Attention Energy 계산\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 마스크(mask)를 사용하는 경우\n",
        "        if mask is not None:\n",
        "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        return x, attention"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzSDUlmOvq6-"
      },
      "source": [
        "#### **Position-wise Feedforward 아키텍처**\n",
        "\n",
        "* 입력과 출력의 차원이 동일합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfNsiED6LSe"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6fWXndvvwJ"
      },
      "source": [
        "#### **인코더(Encoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 인코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 인코더는 인코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwhr1-df6MKk"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N22uqlEmvx06"
      },
      "source": [
        "#### **인코더(Encoder) 아키텍처**\n",
        "\n",
        "* 전체 인코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **input_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j2ZRWaf6M14"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, src_len]\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src # 마지막 레이어의 출력을 반환"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl-eh0mAvzva"
      },
      "source": [
        "#### **디코더(Decoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 디코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 디코더는 디코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "    * 디코더 레이어에서는 두 개의 Multi-Head Attention 레이어가 사용됩니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBalCQMq6Nj4"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 자기 자신에 대하여 어텐션(attention)\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kRYUk-1v1jv"
      },
      "source": [
        "#### **디코더(Decoder) 아키텍처**\n",
        "\n",
        "* 전체 디코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **output_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* Seq2Seq과는 마찬가지로 실제로 추론(inference) 시기에서는 디코더를 반복적으로 넣을 필요가 있습니다.\n",
        "    * 학습(training) 시기에서는 한 번에 출력 문장을 구해 학습할 수 있습니다.\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzJ-DCDt6Oev"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn-yCx4yv348"
      },
      "source": [
        "#### **트랜스포머(Transformer) 아키텍처**\n",
        "\n",
        "* 최종적인 전체 트랜스포머(Transformer) 모델을 정의합니다.\n",
        "* 입력이 들어왔을 때 앞서 정의한 인코더와 디코더를 거쳐 출력 문장을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ignEkCL6PSr"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1TDOflzv5xW"
      },
      "source": [
        "#### **학습(Training)**\n",
        "\n",
        "* 하이퍼 파라미터 설정 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ombHNgO56Q7r"
      },
      "source": [
        "INPUT_DIM = len(korean_voca.word2idx)\n",
        "OUTPUT_DIM = len(english_voca.word2idx)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W-Tr-D06SbJ"
      },
      "source": [
        "SRC_PAD_IDX = korean_voca.word2idx[korean_voca.PAD]\n",
        "TRG_PAD_IDX = english_voca.word2idx[english_voca.PAD]\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1DbVBkVwCvA"
      },
      "source": [
        "* **모델 가중치 파라미터 초기화**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XObg1hxB6bOA",
        "outputId": "586bd857-ff29-4df8-b8d0-f55a03be6697"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 32,738,721 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWItEfu26chy",
        "outputId": "b69c9f6c-2751-488f-8967-e4a2a1e3416e"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(40612, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(35745, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=35745, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Je4gMnSwITT"
      },
      "source": [
        "* 학습 및 평가 함수 정의\n",
        "    * 기본적인 Seq2Seq 모델과 거의 유사하게 작성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_hn64HD6dYK"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg6MC3dK6gF9"
      },
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch[0]\n",
        "        trg = batch[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "\n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEukz7xc6o6F"
      },
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0]\n",
        "            trg = batch[1]\n",
        "\n",
        "            # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "            # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            # output: [배치 크기, trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기, trg_len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4-D3IuNwO9t"
      },
      "source": [
        "* 학습(training) 및 검증(validation) 진행\n",
        "    * **학습 횟수(epoch)**: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuAulfy_6pow"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC-dgh1E6qbF",
        "outputId": "a2d56a7b-f51c-4a4c-d615-f525179d6056"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 4\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer_korean_to_english.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 2m 52s\n",
            "\tTrain Loss: 6.377 | Train PPL: 588.268\n",
            "\tValidation Loss: 5.971 | Validation PPL: 391.921\n",
            "Epoch: 02 | Time: 2m 55s\n",
            "\tTrain Loss: 5.053 | Train PPL: 156.468\n",
            "\tValidation Loss: 5.642 | Validation PPL: 281.968\n",
            "Epoch: 03 | Time: 2m 55s\n",
            "\tTrain Loss: 4.347 | Train PPL: 77.238\n",
            "\tValidation Loss: 5.556 | Validation PPL: 258.860\n",
            "Epoch: 04 | Time: 2m 55s\n",
            "\tTrain Loss: 3.776 | Train PPL: 43.633\n",
            "\tValidation Loss: 5.591 | Validation PPL: 267.959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw1ntWEV6uth"
      },
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(korean, model, device, max_len=80, logging=True):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    korean = clean_string(korean)\n",
        "    tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [korean_voca.SOS] + tokens + [korean_voca.EOS]\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = []\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            src_indexes.append(korean_voca.word2idx[token])\n",
        "        except KeyError:\n",
        "            src_indexes.append(korean_voca.word2idx[korean_voca.UNK])\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [english_voca.word2idx[english_voca.SOS]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == english_voca.word2idx[english_voca.EOS]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [english_voca.idx2word[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avx76dMr9mXm",
        "outputId": "29530b05-5757-4da1-c482-a79273668d29"
      },
      "source": [
        "example_idx = 15\n",
        "\n",
        "src = korean_lines_test[example_idx]\n",
        "trg = english_lines_test[example_idx]\n",
        "\n",
        "print(f'소스 문장: {src}', end='')\n",
        "print(f'타겟 문장: {trg}', end='')\n",
        "\n",
        "translation, attention = translate_sentence(src, model, device, logging=True)\n",
        "\n",
        "print(\"모델 출력 결과:\", \" \".join(translation))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장: 도쿄의 니케이 지수는 9291.03으로 0.33 퍼센트 하락했다.\n",
            "타겟 문장: Tokyo's Nikkei is off 0.33 percent to 9291.03.\n",
            "전체 소스 토큰: ['<sos>', '도쿄', '의', '니', '케이', '지수', '는', '929103', '으로', '033', '퍼센트', '하락', '했다', '<eos>']\n",
            "소스 문장 인덱스: [2, 24549, 10778, 33268, 26115, 8261, 34752, 0, 4301, 0, 37928, 17533, 3443, 3]\n",
            "모델 출력 결과: tokyo is the lowest level since the stock market and asia <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2360KqGAcHNX"
      },
      "source": [
        "* 어텐션 맵(Attention Map) 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhp1bcE33uU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention, n_heads=8, n_rows=4, n_cols=2):\n",
        "\n",
        "    assert n_rows * n_cols == n_heads\n",
        "\n",
        "    plt.rc('font', family='NanumBarunGothic') # 폰트 설정\n",
        "    fig = plt.figure(figsize=(15, 25)) # 출력할 그림 크기 조절\n",
        "\n",
        "    for i in range(n_heads):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
        "\n",
        "        # 어텐션(Attention) 스코어 확률 값을 이용해 그리기\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>'], rotation=45)\n",
        "        ax.set_yticklabels([''] + translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzlH8RZEcIJF",
        "outputId": "b91ae5c9-6d8e-4836-ce2e-063104ee5617"
      },
      "source": [
        "src = \"남한과 미국은 동맹적인 관계를 유지하고 있다.\"\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "\n",
        "translation, attention = translate_sentence(src, model, device, logging=True)\n",
        "\n",
        "print(\"모델 출력 결과:\", \" \".join(translation))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장: 남한과 미국은 동맹적인 관계를 유지하고 있다.\n",
            "전체 소스 토큰: ['<sos>', '남한', '과', '미국', '은', '동맹', '적', '인', '관계', '를', '유지', '하고', '있다', '<eos>']\n",
            "소스 문장 인덱스: [2, 34155, 31438, 1792, 1742, 9015, 4889, 16996, 31495, 9343, 16172, 29566, 3663, 3]\n",
            "모델 출력 결과: south korea and the united states is a role of the united states <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dnwiCsNlcKkU",
        "outputId": "9b5f160a-b302-4975-8772-3baf38390a28"
      },
      "source": [
        "src = clean_string(src)\n",
        "korean_tokens = [line[0] for line in okt.pos(src, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "display_attention(korean_tokens, translation, attention)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45224 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48120 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51008 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46041 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47609 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51201 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44288 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47484 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54616 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51080 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45224 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48120 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51008 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46041 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47609 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51201 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44288 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47484 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50976 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54616 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51080 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1800 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdEp459kf2Bz"
      },
      "source": [
        "#### <b>BLEU Score 계산</b>\n",
        "\n",
        "* 학습된 트랜스포머(Transformer) 모델의 BLEU 스코어 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76pGgi0IcS6M"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def show_bleu(model, device, max_len=80):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    index = 0\n",
        "\n",
        "    for i in range(len(korean_lines_test)):\n",
        "        src = korean_lines_test[i]\n",
        "        trg = english_lines_test[i]\n",
        "\n",
        "        trg = clean_string(trg)\n",
        "        trg = trg.split(' ')\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, model, device, max_len, logging=False)\n",
        "\n",
        "        # 마지막 <eos> 토큰 제거\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "        index += 1\n",
        "        if (index + 1) % 100 == 0:\n",
        "            print(f\"[{index + 1}/{len(korean_lines_test)}]\")\n",
        "            print(f\"예측: {pred_trg}\")\n",
        "            print(f\"정답: {trg}\")\n",
        "\n",
        "    bleu = bleu_score(pred_trgs, trgs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
        "    print(f'Total BLEU Score = {bleu*100:.2f}')\n",
        "\n",
        "    individual_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "    individual_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 1, 0, 0])\n",
        "    individual_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 1, 0])\n",
        "    individual_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 0, 1])\n",
        "\n",
        "    print(f'Individual BLEU1 score = {individual_bleu1_score*100:.2f}') \n",
        "    print(f'Individual BLEU2 score = {individual_bleu2_score*100:.2f}') \n",
        "    print(f'Individual BLEU3 score = {individual_bleu3_score*100:.2f}') \n",
        "    print(f'Individual BLEU4 score = {individual_bleu4_score*100:.2f}') \n",
        "\n",
        "    cumulative_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "    cumulative_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/2, 1/2, 0, 0])\n",
        "    cumulative_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/3, 1/3, 1/3, 0])\n",
        "    cumulative_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/4, 1/4, 1/4, 1/4])\n",
        "\n",
        "    print(f'Cumulative BLEU1 score = {cumulative_bleu1_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU2 score = {cumulative_bleu2_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU3 score = {cumulative_bleu3_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU4 score = {cumulative_bleu4_score*100:.2f}') "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuh4aVgCf3MU",
        "outputId": "f9a9d47f-480f-4e92-be7a-943f680bcde2"
      },
      "source": [
        "show_bleu(model, device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100/2000]\n",
            "예측: ['the', 'international', 'olympic', 'committee', 'said', 'that', 'the', 'international', 'olympic', 'committee', 'will', 'not', 'be', 'made', 'by', 'the', 'international', 'olympic', 'committee', 'of', 'the', 'international', 'olympic', 'gold', 'medal', 'in', 'the', 'international', 'community']\n",
            "정답: ['the', 'skull', 'nicknamed', 'toumai', 'found', 'in', 'northern', 'chad', 'by', 'an', 'international', 'team', 'is', 'not', 'part', 'of', 'the', 'human', 'family', 'tree']\n",
            "[200/2000]\n",
            "예측: ['he', 'said', 'the', 'death', 'toll', 'was', 'not', 'known', 'as', 'the', 'death', 'of', 'the', 'death', 'penalty', 'and', 'was', 'conceived', 'by', 'the', 'death', 'penalty', 'in', 'the', 'late', 'april', '29']\n",
            "정답: ['johnsons', 'eviscerated', 'body', 'which', 'police', 'said', 'they', 'found', 'after', 'receiving', 'calls', 'about', 'a', 'foul', 'odor', 'coming', 'from', 'the', 'apartment', 'was', 'in', 'a', 'state', 'of', 'moderate', 'decomposition', 'and', 'she', 'had', 'been', 'dead', 'about', 'two', 'days', 'medical', 'examiner', 'karl', 'williams', 'said']\n",
            "[300/2000]\n",
            "예측: ['the', 'study', 'was', 'the', 'largest', 'number', 'of', 'cases', 'in', 'the', 'journal', 'of', 'the', 'worlds', 'largest', 'level', 'of', 'alcohol', 'which', 'could', 'be', 'able', 'to', 'increase', 'the', 'number', 'of', 'dollars', 'in', 'the', 'highest', 'level']\n",
            "정답: ['studies', 'show', 'productivity', 'drops', 'when', 'temperatures', 'dip', 'below', '72', 'degrees']\n",
            "[400/2000]\n",
            "예측: ['he', 'said', 'he', 'had', 'been', 'arrested', 'on', 'charges', 'stemming', 'from', 'his', 'wife', 'and', 'drug', 'charges', 'against', 'him']\n",
            "정답: ['the', 'couple', 'who', 'face', 'charges', 'of', 'bodily', 'harm', 'making', 'threats', 'and', 'coercion', 'were', 'released', 'on', 'bail', 'thursday', 'he', 'said']\n",
            "[500/2000]\n",
            "예측: ['israel', 'has', 'been', 'released', 'by', 'a', 'palestinian', 'medical', 'medical', 'examiners', 'office', 'in', 'gaza']\n",
            "정답: ['israel', 'on', 'wednesday', 'also', 'released', 'the', 'remains', 'of', '199', 'fighters', 'from', 'lebanon']\n",
            "[600/2000]\n",
            "예측: ['the', 'us', 'geological', 'survey', 'struck', 'a', 'magnitude', 'of', '71', 'magnitude', '79', 'according', 'to', 'the', 'us', 'geological', 'survey']\n",
            "정답: ['a', 'strong', 'earthquake', 'struck', 'monday', 'near', 'some', 'greek', 'islands', 'close', 'to', 'the', 'turkish', 'coast', 'according', 'to', 'the', 'us', 'geological', 'service']\n",
            "[700/2000]\n",
            "예측: ['the', 'last', 'month', 'the', 'announcement', 'came', 'after', 'the', 'last', 'month', 'was', 'announced', 'last', 'month', 'but', 'the', 'company', 'had', 'already', 'made', 'it', 'easier', 'to', 'cut', 'its', 'profits']\n",
            "정답: ['inbevs', 'original', 'offer', 'of', '46', 'billion', 'made', 'on', 'june', '11th', 'was', 'rejected', 'as', 'too', 'low']\n",
            "[800/2000]\n",
            "예측: ['but', 'the', 'plane', 'had', 'been', 'able', 'to', 'get', 'more', 'than', 'a', 'million', 'tons', 'of', 'fuel', 'prices', 'for', 'the', 'air', 'or', 'a', 'year']\n",
            "정답: ['but', 'she', 'points', 'out', 'that', 'the', 'jewelry', 'is', 'almost', 'always', 'made', 'from', 'cheap', 'metal', 'that', 'will', 'turn', 'yellow', 'or', 'lose', 'its', 'sheen', 'within', 'weeks']\n",
            "[900/2000]\n",
            "예측: ['iran', 'has', 'been', 'shut', 'down', 'its', 'main', 'nuclear', 'reactor', 'and', 'a', 'week', 'after', 'the', 'un', 'nuclear', 'watchdog', 'reported']\n",
            "정답: ['iranian', 'media', 'reported', 'that', 'tehran', 'fired', 'a', 'series', 'of', 'missiles', 'on', 'thursday', 'in', 'a', 'second', 'day', 'of', 'longrange', 'missile', 'testing']\n",
            "[1000/2000]\n",
            "예측: ['police', 'said', 'they', 'were', 'arrested', 'and', 'they', 'were', 'arrested', 'by', 'a', 'man', 'who', 'was', 'in', 'a', 'hospital', 'where', 'they', 'were', 'crying', 'out', 'to', 'be', 'a', 'man', 'and', 'to', 'be', 'a', 'man', 'said', 'thursday']\n",
            "정답: ['when', 'police', 'surrounded', 'the', 'men¡¯s', 'apartment', 'tuesday', 'they', 'found', '15', 'men', 'and', 'women', 'wielding', 'knives', 'and', 'shouting', '¡°sacrifice', 'for', 'allah¡±', 'a', 'police', 'spokesman', 'told', 'xinhua']\n",
            "[1100/2000]\n",
            "예측: ['north', 'korea', 'has', 'agreed', 'to', 'resume', 'its', 'nuclear', 'program', 'since', 'last', 'month']\n",
            "정답: ['north', 'korea', 'declared', 'details', 'of', 'its', 'nuclear', 'program', 'last', 'month']\n",
            "[1200/2000]\n",
            "예측: ['president', 'george', 'w', 'bush', 'said', 'he', 'was', 'a', 'good', 'step', 'toward', 'the', 'united', 'states']\n",
            "정답: ['president', 'bush', 'gave', 'a', 'positive', 'but', 'cautious', 'assessment', 'of', 'russia¡¯s', 'new', 'president', 'dmitry', 'medvedev']\n",
            "[1300/2000]\n",
            "예측: ['the', 'worlds', 'largest', 'makers', 'are', 'able', 'to', 'sell', 'cars', 'for', 'the', 'first', 'time', 'but', 'it', 'is', 'not', 'a', 'little', 'bit', 'more', 'than', 'ever', 'seen', 'in', 'the', 'world']\n",
            "정답: ['von', 'hagens', 'says', 'he', 'relies', 'on', 'donors', 'not', 'only', 'as', 'a', 'source', 'of', 'specimens', 'but', 'also', 'as', 'representations', 'of', 'body', 'worlds', 'philosophy']\n",
            "[1400/2000]\n",
            "예측: ['ma', 'yingjeou', 'has', 'been', 'cultivating', 'ties', 'with', 'the', 'former', 'prime', 'minister', 'and', 'has', 'been', 'elected']\n",
            "정답: ['taiwans', 'new', 'president', 'ma', 'yingjeou', 'has', 'rejected', 'the', 'push', 'for', 'independence']\n",
            "[1500/2000]\n",
            "예측: ['the', 'new', 'york', 'times', 'says', 'he', 'is', 'a', 'new', 'album', 'to', 'make', 'the', 'first', 'album', 'of', 'allnew', 'material', 'the', 'new', 'york', 'times']\n",
            "정답: ['walter', 'scott', '24', 'put', 'his', 'soul', 'up', 'for', 'sale', 'on', 'new', 'zealand', 'internet', 'auction', 'site', 'trademe', 'and', 'so', 'far', 'has', 'received', 'more', 'than', '100', 'expressions', 'of', 'interest']\n",
            "[1600/2000]\n",
            "예측: ['north', 'korea', 'has', 'been', 'criticized', 'for', 'saying', 'it', 'was', 'a', 'key', 'reason', 'to', 'take', 'over', 'north', 'korea']\n",
            "정답: ['but', 'the', 'governing', 'uri', 'party', 'still', 'underlined', 'the', 'importance', 'of', 'interkorean', 'economic', 'projects']\n",
            "[1700/2000]\n",
            "예측: ['officials', 'said', 'the', 'soldiers', 'were', 'killed', 'in', 'the', 'area', 'where', 'the', 'boy', 'died']\n",
            "정답: ['regional', 'officials', 'said', 'he', 'died', 'in', 'a', 'shootout', 'when', 'marines', 'swooped', 'on', 'his', 'hideout', 'in', 'the', 'island', 'of', 'tawitawi']\n",
            "[1800/2000]\n",
            "예측: ['the', 'un', 'envoy', 'ibrahim', 'gambari', 'has', 'said', 'it', 'was', 'not', 'to', 'be', 'able', 'to', 'return', 'to', 'the', 'un']\n",
            "정답: ['the', 'move', 'was', 'opposed', 'by', 'the', 'party', 'of', 'president', 'nicolas', 'sarkozy', 'who', 'has', 'been', 'trying', 'to', 'ease', 'tense', 'ties', 'with', 'beijing']\n",
            "[1900/2000]\n",
            "예측: ['the', 'dow', 'is', 'up', 'down', 'about', '9', 'points']\n",
            "정답: ['right', 'now', 'the', 'dow', 'is', 'up', '14', 'points']\n",
            "[2000/2000]\n",
            "예측: ['japan', 'is', 'at', 'least', 'one', 'of', 'the', 'dead', 'at', 'least', 'one', 'of', 'the', 'dead', 'at', 'least', 'one', 'people']\n",
            "정답: ['japans', 'derailed', 'commuter', 'train', 'accident', 'has', 'killed', 'at', 'least', '69', 'people']\n",
            "Total BLEU Score = 2.06\n",
            "Individual BLEU1 score = 20.98\n",
            "Individual BLEU2 score = 3.74\n",
            "Individual BLEU3 score = 0.92\n",
            "Individual BLEU4 score = 0.25\n",
            "Cumulative BLEU1 score = 20.98\n",
            "Cumulative BLEU2 score = 8.86\n",
            "Cumulative BLEU3 score = 4.17\n",
            "Cumulative BLEU4 score = 2.06\n"
          ]
        }
      ]
    }
  ]
}